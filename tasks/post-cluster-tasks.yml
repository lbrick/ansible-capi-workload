---
- name: Initialize Deployment Section
  ansible.builtin.lineinfile:
    path: "{{ templates_dir }}/README.md"
    line: "## Deployment Order"
    create: yes
    state: present

- name: Add Terraform commands
  ansible.builtin.lineinfile:
    path: "{{ templates_dir }}/README.md"
    line: "cd terraform && terraform init && terraform apply"
    insertafter: "## Deployment Order"

- name: Find Cluster Manifests
  ansible.builtin.find:
    paths: 
      - "{{ cluster_templates }}"
    patterns: "*.yml,*.yaml"
    recurse: yes
  register: cluster_manifests

- name: Add Cluster Manifests to README
  ansible.builtin.lineinfile:
    path: "{{ templates_dir }}/README.md"
    line: "kubectl --kubectl /path/to/workload/cluster/kubeconfig apply -f {{ item.path }}"
    insertafter: EOF
  with_items: "{{ cluster_manifests.files | sort(attribute='path') }}"

- name: Find Core Manifests
  ansible.builtin.find:
    paths: 
      - "{{ cluster_apps }}"
    patterns: "*.yml,*.yaml"
    recurse: yes
  register: core_manifests

- name: Add Core Manifests to README
  ansible.builtin.lineinfile:
    path: "{{ templates_dir }}/README.md"
    line: "kubectl --kubectl /path/to/workload/cluster/kubeconfig apply -f {{ item.path }}"
    insertafter: EOF
  with_items: "{{ core_manifests.files | sort(attribute='path') }}"

- name: Add Nvidia Setup steps to README
  ansible.builtin.lineinfile:
    path: "{{ templates_dir }}/README.md"
    line: "{{ item }}"
    insertafter: EOF
    create: yes
  with_items:
    - "" # Adds a newline for spacing
    - "### Nvidia GPU Operator Setup"
    - "helm --kubectl /path/to/workload/cluster/kubeconfig repo add nvidia https://helm.ngc.nvidia.com/nvidia"
    - "helm --kubectl /path/to/workload/cluster/kubeconfig repo update"
    - "helm --kubectl /path/to/workload/cluster/kubeconfig install nvidia-gpu-operator -n gpu-operator --create-namespace nvidia/gpu-operator --version=v{{ nvidia_gpu_operator_version }} --set toolkit.version=v{{ nvidia_container_toolkit_version }}-ubi8"
    - "kubectl --kubectl /path/to/workload/cluster/kubeconfig create -n gpu-operator -f ./cluster-support-services/gpu-{{ nvidia_gpu_sharing_type }}-config-all.yml"
    - "kubectl --kubectl /path/to/workload/cluster/kubeconfig patch clusterpolicies.nvidia.com/cluster-policy -n gpu-operator --type merge -p '{\"spec\": {\"devicePlugin\": {\"config\": {\"name\": \"{{ nvidia_gpu_sharing_type }}-config-all\", \"default\": \"any\"}}}}'"
  when: 
  - enable_gpu_nodes == true
  - (gpu_operator | default('nvidia')) == "nvidia"

- name: Find Support Service Manifests
  ansible.builtin.find:
    paths:
      - "{{ cluster_support_apps }}"
    patterns: "*.yml,*.yaml"
  register: support_manifests

- name: Add Support Services with unique command
  ansible.builtin.lineinfile:
    path: "{{ templates_dir }}/README.md"
    line: "kubectl --kubectl /path/to/mgmt/cluster/kubeconfig apply -f {{ item.path }}"
    insertafter: EOF
  with_items: "{{ support_manifests.files | sort(attribute='path') }}"